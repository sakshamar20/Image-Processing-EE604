{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image):\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D:\\Assignment 1\\Q1\\\\test\\\\9.png\"\n",
    "image= cv2.imread(image_path,cv2.IMREAD_UNCHANGED)\n",
    "if image is None:\n",
    "    print(\"Error: Unable to load image.\")\n",
    "show(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 482, 4)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "if image.shape[-1] == 4:\n",
    "    image[image[:, :, 3] < 240] = [0,0,0,255]  \n",
    "    \n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Apply Gaussian blur to reduce noise and improve contour detection\n",
    "# blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# # Threshold the image\n",
    "# _, thresholded = cv2.threshold(blurred, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# # Find contours\n",
    "# contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# quadrilaterals = []\n",
    "\n",
    "# for contour in contours:\n",
    "#     if len(contour) == 4:\n",
    "#         quadrilaterals.append(contour)\n",
    "\n",
    "# for quadrilateral in quadrilaterals:\n",
    "#     cv2.drawContours(thresholded, [quadrilateral], -1, (0, 255, 0), 2)\n",
    "\n",
    "# show(thresholded)\n",
    "# contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# # blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "# # show(blurred)\n",
    "# # edges = cv2.Canny(blurred, 100,200)\n",
    "# # contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # quadrilateral_corners = []\n",
    "# # for contour in contours:\n",
    "# #     epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "# #     approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "# #     if len(approx) == 4:\n",
    "# #         quadrilateral_corners.append(approx)\n",
    "\n",
    "# # for corners in quadrilateral_corners:\n",
    "# #     cv2.drawContours(blurred, [corners], 0, (0, 255, 0), 2)\n",
    "\n",
    "# # show(blurred)\n",
    "# blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "# gray = np.float32(gray)\n",
    "# ret, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "# contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # show(thresh)\n",
    "# # corners = cv2.cornerHarris(thresh, blockSize=2, ksize=3, k=0.04)\n",
    "# # # corners\n",
    "# # threshold = 0.01 * corners.max()\n",
    "# # corner_image = thresh.copy()\n",
    "# # show(corner_image)\n",
    "\n",
    "# # for i in range(corners.shape[0]):\n",
    "# #     for j in range(corners.shape[1]):\n",
    "# #         if corners[i, j] > threshold:\n",
    "#             cv2.circle(corner_image, (j, i), 5, (0, 0, 255), 2)\n",
    "# show(corner_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([370,   2], dtype=int32), array([148,   9], dtype=int32), array([  2, 472], dtype=int32), array([479, 472], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = gray_image\n",
    "cv2.imwrite(\"gray.jpg\", gray_image)\n",
    "ret, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for contour in contours:\n",
    "    points = cv2.approxPolyDP(contour, 0.04 * cv2.arcLength(contour, True), True)\n",
    "\n",
    "p = []\n",
    "\n",
    "for point in points:\n",
    "    p.append(point[0])\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = sorted(p, key=lambda x: x[0])\n",
    "temp = p[1]\n",
    "if(p[0][1] > p[1][1]):\n",
    "    p[1] = p[0]\n",
    "    p[0] = temp\n",
    "temp = p[2]\n",
    "if(p[2][1] < p[3][1]):\n",
    "    p[2] = p[3]\n",
    "    p[3] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.   9.]\n",
      " [  2. 472.]\n",
      " [479. 472.]\n",
      " [370.   2.]] [[  0.   0.]\n",
      " [  0. 600.]\n",
      " [600. 600.]\n",
      " [600.   0.]]\n"
     ]
    }
   ],
   "source": [
    "pts1 = np.float32(p)\n",
    "pts2 = np.float32([[0,0],[0,600],[600,600],[600,0]])\n",
    "print(pts1,pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "dst = cv2.warpPerspective(image,M,(600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "# sharpened_image = cv2.filter2D(dst, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"test_image.jpg\", dst)\n",
    "cv2.imshow(\"Image\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = dst[:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define color thresholds\n",
    "green_color = np.array([0, 128, 1], dtype=np.uint8)\n",
    "orange_color = np.array([255, 153, 52], dtype=np.uint8)\n",
    "tolerance = [10,10,10]  # Adjust this value to control the color matching tolerance\n",
    "\n",
    "# Create masks for pixels that are close to the perfect colors\n",
    "green_mask = cv2.inRange(dst, green_color - tolerance, green_color + tolerance)\n",
    "orange_mask = cv2.inRange(dst, orange_color - tolerance, orange_color + tolerance)\n",
    "\n",
    "# Create a mask for non-matching pixels\n",
    "non_matching_mask = ~(green_mask | orange_mask)\n",
    "\n",
    "# Set non-matching pixels to white\n",
    "dst[non_matching_mask > 0] = [255, 255, 255]\n",
    "show(dst)\n",
    "cv2.imwrite('processed_image.jpg', dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the blurry image\n",
    "# blurry_image = dst\n",
    "\n",
    "# # Apply denoising to reduce noise\n",
    "# denoised_image = cv2.fastNlMeansDenoisingColored(blurry_image, None, 10, 10, 7, 21)\n",
    "\n",
    "# # Apply sharpening to enhance details\n",
    "# kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "# sharpened_image = cv2.filter2D(denoised_image, -1, kernel)\n",
    "\n",
    "\n",
    "# # Convert to HSV color space\n",
    "# hsv_image = cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# # Define the lower and upper bounds of the color in HSV\n",
    "# lower_bound = np.array([0, 0, 0])\n",
    "# upper_bound = np.array([255, 255, 255])\n",
    "\n",
    "# # Create a mask for the colors within the specified range\n",
    "# mask = cv2.inRange(hsv_image, lower_bound, upper_bound)\n",
    "\n",
    "# # Apply the mask to the original image to extract the flag's colors\n",
    "# extracted_colors = cv2.bitwise_and(sharpened_image, sharpened_image, mask=mask)\n",
    "\n",
    "# # Resize the extracted colors to a higher resolution\n",
    "# enlarged_colors = cv2.resize(extracted_colors, (600,600), interpolation=cv2.INTER_LINEAR)\n",
    "# show(enlarged_colors)\n",
    "# cv2.imwrite('enhanced_flag.jpg', enlarged_colors)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee604",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
